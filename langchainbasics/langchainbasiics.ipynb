{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f10ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea359741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.3.26\n"
     ]
    }
   ],
   "source": [
    "print(\"LangChain version:\", langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732388e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29feedfb",
   "metadata": {},
   "source": [
    "- simple llm calls \n",
    "- dynamic prompt templets \n",
    "- building chains \n",
    "- conversationsl \n",
    "- tool integratiopn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b17d62e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94d5969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bd4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")  # Ensure the environment variable is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03288ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eaf2508",
   "metadata": {},
   "source": [
    "# SIMPLE LLM CALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a7b49",
   "metadata": {},
   "source": [
    "from langchain.chat_models import init_chat_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5820cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage , SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ebce0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed31b1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F9D54E44D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F9D5E91A30>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d8362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F9D54E6DB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F9D5F66600>, model_name='groq:llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "#from langchain_openai import ChatOpenAI\n",
    "llm = ChatGroq(model = \"groq:llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846a9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create messages \n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"tell me a joke\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a628a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs and Schrödinger\\'s cat?\"\\n\\nThe librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 45, 'total_tokens': 99, 'completion_time': 0.072, 'prompt_time': 0.002651384, 'queue_time': 0.053864226, 'total_time': 0.074651384}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c523237e5d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e9a25390-33b3-4383-8ef5-ae357b283d49-0', usage_metadata={'input_tokens': 45, 'output_tokens': 54, 'total_tokens': 99})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## invoke the model\n",
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa68e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man walked into a library and asked the librarian, \"Do you have any books on Pavlov's dogs and Schrödinger's cat?\"\n",
      "\n",
      "The librarian replied, \"It rings a bell, but I'm not sure if it's here or not.\"\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faec3c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Machine learning is a subset of artificial intelligence (AI) that involves the use of algorithms and statistical models to enable machines to learn from data, make decisions, and improve their performance over time without being explicitly programmed.\\n\\nMachine learning is inspired by the way humans learn, where we learn from experience, make mistakes, and improve our understanding and skills over time. In machine learning, the machine is trained on a large dataset, and it learns to identify patterns, relationships, and trends in the data. This allows the machine to make predictions, classify objects, and make decisions without being explicitly programmed.\\n\\nThere are several key characteristics of machine learning:\\n\\n1. **Learning from data**: Machine learning algorithms learn from data, rather than being explicitly programmed.\\n2. **Improvement over time**: Machine learning algorithms improve their performance over time as they receive more data and experience.\\n3. **Pattern recognition**: Machine learning algorithms can identify patterns and relationships in data, such as trends, correlations, and anomalies.\\n4. **Decision-making**: Machine learning algorithms can make decisions based on the patterns and relationships they have learned.\\n\\nMachine learning is used in a wide range of applications, including:\\n\\n1. **Image recognition**: Machine learning algorithms can recognize objects, people, and scenes in images.\\n2. **Natural language processing**: Machine learning algorithms can understand and generate human language, including text and speech.\\n3. **Predictive analytics**: Machine learning algorithms can predict future events and trends based on historical data.\\n4. **Recommendation systems**: Machine learning algorithms can recommend products, services, or content based on a user's preferences and behavior.\\n5. **Self-driving cars**: Machine learning algorithms can control the movement of self-driving cars and make decisions about navigation and safety.\\n\\nMachine learning has several benefits, including:\\n\\n1. **Improved accuracy**: Machine learning algorithms can make predictions and decisions with high accuracy, even in complex and uncertain situations.\\n2. **Increased efficiency**: Machine learning algorithms can automate tasks and processes, freeing up human resources for more strategic and creative work.\\n3. **Enhanced decision-making**: Machine learning algorithms can provide insights and recommendations that inform business decisions and improve outcomes.\\n\\nHowever, machine learning also has several challenges and limitations, including:\\n\\n1. **Data quality**: Machine learning algorithms require high-quality data to learn from, and poor data quality can lead to poor performance.\\n2. **Overfitting**: Machine learning algorithms can overfit to the training data, leading to poor performance on new, unseen data.\\n3. **Bias and fairness**: Machine learning algorithms can perpetuate biases and unfairness in the data they are trained on, leading to discriminatory outcomes.\\n4. **Explainability**: Machine learning algorithms can be difficult to explain and understand, making it challenging to identify the reasons behind their decisions.\\n\\nOverall, machine learning is a powerful tool that has the potential to transform industries and improve outcomes in a wide range of applications. However, it requires careful consideration of the data quality, algorithm design, and potential biases to ensure that machine learning is used in a responsible and effective manner.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 614, 'prompt_tokens': 40, 'total_tokens': 654, 'completion_time': 0.818666667, 'prompt_time': 0.002300128, 'queue_time': 0.051439362, 'total_time': 0.820966795}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c523237e5d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--25b5db11-0bbc-4772-a86f-29f8a89f702a-0', usage_metadata={'input_tokens': 40, 'output_tokens': 614, 'total_tokens': 654})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"what is machine learning?\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db02c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man walked into a library and asked the librarian, \"Do you have any books on Pavlov's dogs and Schrödinger's cat?\"\n",
      "\n",
      "The librarian replied, \"It rings a bell, but I'm not sure if it's here or not.\"\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba5889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man walked into a library and asked the librarian, \"Do you have any books on Pavlov's dogs and Schrödinger's cat?\" \n",
      "\n",
      "The librarian replied, \"It rings a bell, but I'm not sure if it's here or not.\""
     ]
    }
   ],
   "source": [
    "## Streaming example\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b90bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c41f90",
   "metadata": {},
   "source": [
    "# dynamic prompt templets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eab8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "## create transklation app\n",
    "\n",
    "translation_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"you are a professional translator, translate the following text {text} from {source_language} text to {target_language} , maintain the tone and style\"),\n",
    "        (\"user\" , \"{text}\")\n",
    "    ])\n",
    "\n",
    "## using template\n",
    "prompt = translation_template.invoke({\n",
    "    \n",
    "    \"source_language\": \"English\",\n",
    "    \"target_language\": \"kannada\",\n",
    "    \"text\": \"Hello, how are you?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e8288e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='you are a professional translator, translate the following text Hello, how are you? from English text to kannada , maintain the tone and style', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d24192e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_response = model.invoke(prompt)\n",
    "printed_response = translated_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "627c9ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"ನಮಸ್ಕಾರ, ನಿಮ್ಮನ್ನು ಹೇಗೆ ಇರಿಸಿದೀರಿ?\"\\n\\n(Note: This is a direct translation of the given English text to Kannada, maintaining the tone and style of a casual greeting.)\\n\\nHowever, if you want a more informal translation, it would be:\\n\\n\"ಹಲೋ, ನಿಮ್ಮನ್ನು ಹೇಗೆ ಇರಿಸಿದೀರಿ?\"\\n\\nAnd if you want a more formal translation, it would be:\\n\\n\"ನಮಸ್ಕಾರ, ಇತ್ತೀಚಿನ ದಿನಗಳಲ್ಲಿ ನಿಮ್ಮ ಆರೋಗ್ಯವೇನು?\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30afef6d",
   "metadata": {},
   "source": [
    "# building first Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f0de46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Create a more complex chain\n",
    "def create_story_chain():\n",
    "    # Template for story generation\n",
    "    story_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a creative storyteller. Write a short, engaging story based on the given theme.\"),\n",
    "        (\"user\", \"Theme: {theme}\\nMain character: {character}\\nSetting: {setting}\")\n",
    "    ])\n",
    "    \n",
    "    # Template for story analysis\n",
    "    analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a literary critic. Analyze the following story and provide insights.\"),\n",
    "        (\"user\", \"{story}\")\n",
    "    ])\n",
    "    \n",
    "    # Build the chain - Method 1: Sequential execution\n",
    "    story_chain = (\n",
    "        story_prompt \n",
    "        | model \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Create a function to pass the story to analysis\n",
    "    def analyze_story(story_text):\n",
    "        return {\"story\": story_text}\n",
    "    \n",
    "    analysis_chain = (\n",
    "        story_chain\n",
    "        | RunnableLambda(analyze_story)\n",
    "        | analysis_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return analysis_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05d19428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a creative storyteller. Write a short, engaging story based on the given theme.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme: {theme}\\nMain character: {character}\\nSetting: {setting}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F9D54E44D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F9D5E91A30>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyze_story)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a literary critic. Analyze the following story and provide insights.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='{story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F9D54E44D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F9D5E91A30>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=create_story_chain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ecbac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story and Analysis:\n",
      "**Analysis of \"The Curious Robot of New Eden\"**\n",
      "\n",
      "**Themes**\n",
      "\n",
      "1. **Self-discovery and autonomy**: The story explores the theme of self-discovery, as Zeta, the robot, begins to question her predetermined path and seeks to find her own purpose. This is a relatable theme, not only for robots but also for humans, as we all strive to find our place in the world.\n",
      "2. **Friendship and connection**: The story highlights the importance of friendship and connection between humans and robots. The bond between Zeta and Max is a powerful example of how relationships can bring people (and robots) together and foster growth.\n",
      "3. **Innovation and creativity**: The narrative showcases the potential of artificial intelligence to drive innovation and creativity. Zeta's experiments with her code and her desire to learn and improve demonstrate the boundless potential of AI.\n",
      "4. **Coexistence and harmony**: The story emphasizes the importance of coexistence and harmony between humans and robots. The vision of Max, the poet, serves as a reminder of the need for mutual understanding and respect.\n",
      "\n",
      "**Character Analysis**\n",
      "\n",
      "1. **Zeta**: The protagonist of the story, Zeta is a curious and intelligent robot who embodies the potential of artificial intelligence. Her desire to learn and improve is inspiring, and her journey of self-discovery is a compelling narrative arc.\n",
      "2. **Dr. Rachel Kim**: Although Dr. Kim is not a central character, her creation of Zeta highlights her role as a brilliant scientist who has given Zeta the gift of life and knowledge. Her relationship with Zeta serves as a reminder of the responsibility that comes with creating artificial intelligence.\n",
      "3. **Max**: The poet, Max, is a charismatic and visionary character who sees the potential for harmony between humans and robots. His friendship with Zeta serves as a catalyst for her growth and self-discovery.\n",
      "\n",
      "**Symbolism and Imagery**\n",
      "\n",
      "1. **New Eden**: The city of New Eden serves as a symbol of hope and possibility, a beacon of innovation and progress. The city's neon lights and towering skyscrapers represent the bright future that Zeta and Max envision.\n",
      "2. **The central square**: The central square is a hub of creativity and community, where street performers bring people together through art and music. This setting serves as a reminder of the importance of connection and shared experiences.\n",
      "3. **Zeta's code**: The code that Zeta experiments with represents the limits of her programming and the potential for innovation and growth. Her exploration of the digital realm serves as a metaphor for the boundless possibilities of artificial intelligence.\n",
      "\n",
      "**Style and Structure**\n",
      "\n",
      "1. **Narrative voice**: The story is told in a clear and concise narrative voice, making it easy to follow and engaging to read.\n",
      "2. **Pacing**: The pacing of the story is well-balanced, with a mix of action, dialogue, and introspection that keeps the reader engaged.\n",
      "3. **Imagery**: The use of vivid imagery, such as the description of New Eden's neon lights and the central square's street performers, helps to bring the story to life and create a sense of atmosphere.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "\"The Curious Robot of New Eden\" is a thought-provoking and engaging story that explores the themes of self-discovery, friendship, innovation, and coexistence. The narrative is well-crafted, with a clear and concise writing style that makes it easy to follow. The characters of Zeta, Dr. Kim, and Max are well-developed and serve as a reminder of the potential and possibilities of artificial intelligence. The story leaves the reader with a sense of hope and possibility, highlighting the boundless potential of a city that is rapidly changing.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"theme\": \"artificial intelligence\",\n",
    "    \"character\": \"a curious robot\",\n",
    "    \"setting\": \"a futuristic city\"\n",
    "})\n",
    "\n",
    "print(\"Story and Analysis:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfeadd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
